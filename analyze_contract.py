import json
import urllib

import requests
from bs4 import BeautifulSoup
import time
import re
import undetected_chromedriver as uc

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium_stealth import stealth
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
import time


class BscScanScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.session.proxies.update({
            "http": "http://qWD41r:JdCPrA@196.19.121.132:8000"
        })
        self.tokens_dict = {}

    def analyze(self, contract):
        html_top_holders = self.get_top_holders_page(contract)
        if html_top_holders:
            holders_list = self.parse_top_holders(html_top_holders)
            #print(holders_list)
            for holder_info in holders_list:
                html_wallet = self.get_wallet_page(holder_info.get('address'))
                #print(html_wallet)
                if html_wallet:
                    self.parse_token_balances(html_wallet, holder_info.get('address'))
        print(json.dumps(self.tokens_dict, indent=4))
        return self.tokens_dict

    def get_wallet_page(self, address):
        """–ü–æ–ª—É—á–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ—à–µ–ª—å–∫–∞"""
        url = f"https://bscscan.com/address/{address}#asset-tokens"

        try:
            response = self.session.get(url)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None

    def get_top_holders_page(self, contract):


        """–û–±—Ö–æ–¥ Cloudflare —Å –ø–æ–º–æ—â—å—é undetected-chromedriver"""
        try:
            url = f"https://bscscan.com/token/tokenholderchart/{contract}"

            options = uc.ChromeOptions()

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
            options.add_argument('--no-first-run --no-service-autorun --password-store=basic')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_argument('--disable-features=VizDisplayCompositor')
            options.add_argument('--disable-background-timer-throttling')
            options.add_argument('--disable-backgrounding-occluded-windows')
            options.add_argument('--disable-renderer-backgrounding')

            # –î–ª—è —Å–µ—Ä–≤–µ—Ä–∞
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')

            # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π user-agent
            options.add_argument(
                '--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

            print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º undetected-chromedriver...")

            driver = uc.Chrome(
                options=options,
                driver_executable_path='/usr/bin/chromedriver'
            )

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã
            driver.set_page_load_timeout(30)

            print(f"üåê –û—Ç–∫—Ä—ã–≤–∞–µ–º: {url}")
            driver.get(url)

            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            wait = WebDriverWait(driver, 20)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            content_indicators = [
                (By.XPATH, "//table//tr"),
                (By.XPATH, "//div[contains(@class, 'card')]"),
                (By.XPATH, "//a[contains(@href, 'address')]"),
                (By.TAG_NAME, "table")
            ]

            content_loaded = False
            for by, selector in content_indicators:
                try:
                    wait.until(EC.presence_of_element_located((by, selector)))
                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç: {selector}")
                    content_loaded = True
                    break
                except:
                    continue

            if not content_loaded:
                print("‚ö† –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å...")
                '''# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                with open('/tmp/debug_page.html', 'w') as f:
                    f.write(driver.page_source)
                print("üíæ HTML —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ /tmp/debug_page.html")'''
                print(driver.page_source)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è JS
            time.sleep(3)

            html_content = driver.page_source

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
            if "Holders" in html_content and len(html_content) > 10000:
                print("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
                return html_content
            else:
                print("‚ùå –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                return None

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return None
        finally:
            try:
                driver.quit()
            except:
                pass
            '''options = webdriver.ChromeOptions()
            options.add_argument('--headless=new')  # –ù–æ–≤—ã–π headless —Ä–µ–∂–∏–º
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--remote-debugging-port=9222')

            # –û–ø—Ü–∏–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)

            # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π user-agent
            options.add_argument(
                '--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è
            options.add_argument('--disable-web-security')
            options.add_argument('--allow-running-insecure-content')
            options.add_argument('--disable-extensions')
            options.add_argument('--disable-plugins')
            options.add_argument('--disable-images')
            options.add_argument('--blink-settings=imagesEnabled=false')

            # –Ø–∑—ã–∫ –∏ —Ä–µ–≥–∏–æ–Ω
            options.add_argument('--lang=en-US,en;q=0.9')

            # –£–∫–∞–∑—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            options.binary_location = '/usr/bin/chromium-browser'

            service = Service('/usr/bin/chromedriver')

            driver = webdriver.Chrome(service=service, options=options)

            # –£–¥–∞–ª—è–µ–º —Å–≤–æ–π—Å—Ç–≤–∞ webdriver –î–û –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
                'source': 
                           Object.defineProperty(navigator, 'webdriver', {
                               get: () => undefined
                           });
                           Object.defineProperty(navigator, 'plugins', {
                               get: () => [1, 2, 3, 4, 5]
                           });
                           Object.defineProperty(navigator, 'languages', {
                               get: () => ['en-US', 'en']
                           });
                       
            })

            print(f"üîÑ Opening BSCscan: {url}")

            try:
                driver.get(url)

                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
                wait = WebDriverWait(driver, 15)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                selectors_to_check = [
                    "//div[contains(@class, 'card')]",
                    "//table",
                    "//div[contains(text(), 'Holders')]",
                    "//body"
                ]

                page_loaded = False
                for selector in selectors_to_check:
                    try:
                        wait.until(EC.presence_of_element_located((By.XPATH, selector)))
                        print(f"‚úì Found element: {selector}")
                        page_loaded = True
                        break
                    except:
                        continue

                if not page_loaded:
                    print("‚ö† No expected elements found, but continuing...")

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è JS
                time.sleep(3)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                html = driver.page_source
                current_url = driver.current_url

                print(f"üìä Page source length: {len(html)}")
                print(f"üåê Current URL: {current_url}")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –ø–æ–ø–∞–ª–∏ –ª–∏ –º—ã –Ω–∞ –∫–∞–ø—á—É –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
                if "captcha" in html.lower() or "cloudflare" in html.lower():
                    print("‚ùå CAPTCHA or Cloudflare detected")
                    return None

                if "access denied" in html.lower():
                    print("‚ùå Access denied by BSCscan")
                    return None

                if len(html) < 1000:
                    print("‚ùå Page content too short")
                    return None

                print("‚úÖ Page loaded successfully")
                return html

            except Exception as page_error:
                print(f"‚ùå Page loading error: {page_error}")
                return None

            finally:
                driver.quit()

        except Exception as e:
            print(f"‚ùå Selenium setup error: {e}")'''


        """–ü–æ–ª—É—á–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞
        url = f"https://bscscan.com/token/tokenholderchart/{contract}"
        '''options = Options()
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        options.add_argument('--disable-blink-features=AutomationControlled')'''
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--remote-debugging-port=9222')

        # –Ø–≤–Ω–æ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ Chrome
        #options.binary_location = '/usr/bin/google-chrome'
        options.binary_location = '/usr/bin/chromium-browser'
        # –î–ª—è Selenium 4.x –∏ –≤—ã—à–µ
        from selenium.webdriver.chrome.service import Service
        service = Service('/usr/bin/chromedriver')

        driver = webdriver.Chrome(service=service, options=options)
        stealth(driver,
                languages=["en-US", "en"],
                vendor="Google Inc.",
                platform="Win32",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True,
                )



        #driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(8)
        html = driver.page_source
        driver.quit()
        #print(html)
        return html"""

    def parse_top_holders(self, html_content):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–ø —Ö–æ–ª–¥–µ—Ä–æ–≤ –∏–∑ HTML"""
        holders = []
        address = None
        soup = BeautifulSoup(html_content, 'html.parser')
        #print(soup)
        holder_rows = soup.find_all('tr')
        #print(holder_rows)
        for info in holder_rows:

            link = info.find('a')


            if link:

                name = link.get_text(strip=True)
                #address = link.get('data-highlight-target')
                if link and link.has_attr('href'):
                    href_value = link['href']
                    # –†–∞–∑–±–∏—Ä–∞–µ–º URL –Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ
                    parsed_url = urllib.parse.urlparse(href_value)
                    # –†–∞–∑–¥–µ–ª—è–µ–º –ø—É—Ç—å –ø–æ —Å–∏–º–≤–æ–ª—É '/' –∏ –±–µ—Ä–µ–º –Ω—É–∂–Ω—É—é —á–∞—Å—Ç—å
                    address = parsed_url.query[2:]

            quantity_list = info.find_all('td')
            if quantity_list:
                for q in quantity_list:
                    q = q.get_text(strip=True)
                    try:
                        quantity = float(q.replace(',',''))
                    except:
                        if '%' in q:
                            percent = float(q.replace(',', '').replace('%', ''))


            if address:
                #print('address', address, 'name', name, 'quantity', quantity, 'percent', percent)
                if '0x' in name:
                    holders.append({
                        'address': address,
                        'name': name,
                        'quantity': quantity,
                        'percent': percent
                    })
        return holders

    def parse_token_balances(self, html_content, holder_address):
        """–ü–∞—Ä—Å–∏–Ω–≥ –±–∞–ª–∞–Ω—Å–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ HTML"""
        soup = BeautifulSoup(html_content, 'html.parser')
        #print(soup)
        tokens = []

        # –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã —Å —Ç–æ–∫–µ–Ω–∞–º–∏
        token_table = soup.find_all('tr')
        count = 0
        quantity = None
        usd_value  =None
        #print(token_table)
        for info in token_table:
            #print(info)
            i = info.find('a', class_='link-muted')
            if not i:
                continue
            chain = i.text
            i = info.find('a', class_='link-dark hash-tag text-truncate')
            if not i:
                continue
            #print(i)
            name = i.text
            if name == 'Visit website extrabnb .net to claim rewards (Visit website extrabnb .net to claim rewards)':
                name = None
            if i and i.has_attr('href'):
                href_value = i['href']
                # –†–∞–∑–±–∏—Ä–∞–µ–º URL –Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ
                parsed_url = urllib.parse.urlparse(href_value)
                # –†–∞–∑–¥–µ–ª—è–µ–º –ø—É—Ç—å –ø–æ —Å–∏–º–≤–æ–ª—É '/' –∏ –±–µ—Ä–µ–º –Ω—É–∂–Ω—É—é —á–∞—Å—Ç—å
                path_parts = parsed_url.path.split('/')
                # –ê–¥—Ä–µ—Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ - —ç—Ç–æ —á–∞—Å—Ç—å –ø—É—Ç–∏, –∏–¥—É—â–∞—è –ø–æ—Å–ª–µ '/token/'
                address = path_parts[2] if len(path_parts) > 2 else None
            number_list = info.find_all('td')
            for n in number_list:
                if not('%' in  n.text or '$' in n.text):
                    try:
                        quantity = round(float(n.text.replace(',', '')), 0)
                    except:
                        continue
                if n.get('data-totalval'):
                    usd_value = int(round(float(n.get('data-totalval')), 0))


            '''token_table = soup.find_all('li',  class_='nav-item list-custom-ERC20')
        count = 0
        for info in token_table:
            #print(info)
            name = info.find('span', class_='list-name hash-tag text-truncate').find('span').get('data-bs-title')
            if name == 'Visit website extrabnb .net to claim rewards (Visit website extrabnb .net to claim rewards)':
                name = None

            link = info.find('a')

            if link and link.has_attr('href'):
                href_value = link['href']
                # –†–∞–∑–±–∏—Ä–∞–µ–º URL –Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∏–µ
                parsed_url = urllib.parse.urlparse(href_value)
                # –†–∞–∑–¥–µ–ª—è–µ–º –ø—É—Ç—å –ø–æ —Å–∏–º–≤–æ–ª—É '/' –∏ –±–µ—Ä–µ–º –Ω—É–∂–Ω—É—é —á–∞—Å—Ç—å
                path_parts = parsed_url.path.split('/')
                # –ê–¥—Ä–µ—Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ - —ç—Ç–æ —á–∞—Å—Ç—å –ø—É—Ç–∏, –∏–¥—É—â–∞—è –ø–æ—Å–ª–µ '/token/'
                address = path_parts[2] if len(path_parts) > 2 else None


            quantity = info.find('span', class_='text-muted').get_text(strip=True).split(' ')[0]
            usd_value = info.find('div', class_='list-usd-value').get_text(strip=True)
            usd_value = 0 if usd_value == '' else float(usd_value.replace(',', '')[1:])'''


            #print(name, address, quantity, usd_value)
            if usd_value > 100:
                tokens.append(
                    {
                        'chain': chain,
                        'name':  name,
                        'address': address,
                        'quantity': quantity,
                        'usd_value': usd_value
                    }
                )
        #print(tokens)
        sorted_tokens = sorted(tokens, key=lambda x: x['usd_value'], reverse=True)
        #print(sorted_tokens[0:10])
        if len(sorted_tokens) >= 2:
            self.tokens_dict[holder_address] = sorted_tokens[0:10]
        return tokens



# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
'''contract = "0xd98438889Ae7364c7E2A3540547Fad042FB24642".lower()
scraper = BscScanScraper()
scraper.analyze(contract)'''
'''html_wallet = scraper.get_wallet_page('0x4858821da3a75c001a895072305b774af7a494d9')
#print(html_wallet)
if html_wallet:
    tokens = scraper.parse_token_balances(html_wallet, 'c')'''
    #print(tokens)
